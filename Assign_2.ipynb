{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4663418-2cc6-4a2e-a76a-78025268ee16",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow-datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b92e63a2-b855-4fe0-b55e-ecc8602c1306",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Embedding\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b49593b-a4e2-4cd2-9f5b-026b06544a31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total datasets available: 438\n",
      "First 20 datasets:\n",
      " ['abstract_reasoning', 'accentdb', 'aeslc', 'aflw2k3d', 'ag_news_subset', 'ai2_arc', 'ai2_arc_with_ir', 'ai2dcaption', 'aloha_mobile', 'amazon_us_reviews', 'anli', 'answer_equivalence', 'arc', 'asimov_dilemmas_auto_val', 'asimov_dilemmas_scifi_train', 'asimov_dilemmas_scifi_val', 'asimov_injury_val', 'asimov_multimodal_auto_val', 'asimov_multimodal_manual_val', 'asqa']\n"
     ]
    }
   ],
   "source": [
    "#list of datasets present in tensorflow\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "all_datasets = tfds.list_builders()\n",
    "print(\"Total datasets available:\", len(all_datasets))\n",
    "print(\"First 20 datasets:\\n\", all_datasets[:20]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "793651da-7f8b-41af-b951-d53d1ddf929f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import imdb #Import the imdb dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b42273ef-1b92-4889-87fb-32a02aa344dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = 10000 #use top 10,000 words only\n",
    "(x_train,y_train),(x_test,y_test) = imdb.load_data(num_words = num_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e57b6e19-5888-42cc-8d70-dc7789f2cf6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 25000\n",
      "Test samples: 25000\n"
     ]
    }
   ],
   "source": [
    "print(\"Training samples:\",len(x_train))\n",
    "print(\"Test samples:\",len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "274237fa-9ace-493d-8e20-9143c905a0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data (pad sequences to ensure uniform input size)\n",
    "maxlen = 500  # Maximum review length in words\n",
    "x_train = pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = pad_sequences(x_test, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c235d32e-dfd2-4da8-8bcc-4e1edccf6ce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\sanya\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Build the Deep Neural Network model\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=num_words, output_dim=32, input_length=maxlen),  # Word embedding layer\n",
    "    Flatten(),  # Flatten to feed into dense layers\n",
    "    Dense(128, activation='relu'),  # First hidden layer\n",
    "    Dense(64, activation='relu'),   # Second hidden layer\n",
    "    Dense(1, activation='sigmoid')  # Output layer for binary classification\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "03c2df06-d8f1-4442-84b7-f16458049956",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\sanya\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6b72bc5d-219f-484b-ad42-9ceb23459e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\sanya\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sanya\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 22s 50ms/step - loss: 0.4104 - accuracy: 0.7888 - val_loss: 0.2877 - val_accuracy: 0.8767\n",
      "Epoch 2/5\n",
      "391/391 [==============================] - 18s 47ms/step - loss: 0.1144 - accuracy: 0.9595 - val_loss: 0.3624 - val_accuracy: 0.8574\n",
      "Epoch 3/5\n",
      "391/391 [==============================] - 19s 48ms/step - loss: 0.0178 - accuracy: 0.9948 - val_loss: 0.6208 - val_accuracy: 0.8449\n",
      "Epoch 4/5\n",
      "391/391 [==============================] - 19s 48ms/step - loss: 0.0034 - accuracy: 0.9991 - val_loss: 0.7892 - val_accuracy: 0.8563\n",
      "Epoch 5/5\n",
      "391/391 [==============================] - 18s 47ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.8601 - val_accuracy: 0.8512\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1d330e0f710>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=5, batch_size=64, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ed242f53-b7dc-4fe4-8d86-dc6c2adf36af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 4s 5ms/step - loss: 0.8601 - accuracy: 0.8512\n",
      "\n",
      "Test Accuracy: 0.8512\n"
     ]
    }
   ],
   "source": [
    "#Evaluate the model\n",
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "print(f\"\\nTest Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7346c1a2-36b7-4644-9442-a5cfcb7d4f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show predictions on a few test samples\n",
    "\n",
    "word_index = imdb.get_word_index() # Get the word-to-index mapping used in the IMDB dataset\n",
    "\n",
    "reverse_word_index = {value: key for key, value in word_index.items()} # Create a reverse mapping from index to word (to decode reviews back to text)\n",
    "\n",
    "def decode_review(encoded_review):\n",
    "    return ' '.join([reverse_word_index.get(i - 3, '?') for i in encoded_review if i >= 3])  # - Subtract 3 (because indices 0, 1, and 2 are reserved for special tokens)\n",
    "                                                                                             # - Get the corresponding word from reverse_word_index\n",
    "                                                                                             # - If index is not found, use '?' as a placeholder\n",
    "                                                                                             # - Only process indices >= 3 to skip special tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9a30b218-7b43-4e7d-8c1d-58292883dec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample Predictions:\n",
      "\n",
      "--- Review #6 ---\n",
      "Predicted: Positive\n",
      "Actual:    Positive\n",
      "Review: i'm absolutely disgusted this movie isn't being sold all who love this movie should email disney and increase the demand for it they'd eventually have to sell it then i'd buy copies for everybody i know everything and everybody in this movie did a good job and i haven't figured out why disney hasn't ...\n",
      "--------------------------------------------------------------------------------\n",
      "--- Review #7 ---\n",
      "Predicted: Positive\n",
      "Actual:    Positive\n",
      "Review: later used by frank in mr deeds goes to town and meet john but in no one individual is cast as a hero or heroine the story is told through a series of scenes that are combined in a special effect known as montage the editing and selection of short segments to produce a desired effect on the viewer d ...\n",
      "--------------------------------------------------------------------------------\n",
      "--- Review #8 ---\n",
      "Predicted: Positive\n",
      "Actual:    Negative\n",
      "Review: the richard dog is to joan fontaine dog however when bing crosby arrives in town to sell a record player to the emperor his dog is attacked by dog after a revenge attack where is from town a insists that dog must confront dog so that she can overcome her fears this is arranged and the dogs fall in l ...\n",
      "--------------------------------------------------------------------------------\n",
      "--- Review #9 ---\n",
      "Predicted: Positive\n",
      "Actual:    Negative\n",
      "Review: hollywood had a long love affair with bogus nights tales but few of these products have stood the test of time the most memorable were the jon hall maria films which have long since become camp this one is filled with dubbed songs and slapstick it's a truly crop of corn and pretty near today it was  ...\n",
      "--------------------------------------------------------------------------------\n",
      "--- Review #10 ---\n",
      "Predicted: Positive\n",
      "Actual:    Positive\n",
      "Review: this film is where the batman franchise ought to have stopped though i will that the ideas behind batman forever were excellent and could have been easily realised by a competent director as it turned out this was not to be the case br br apparently warner brothers executives were disappointed with  ...\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nSample Predictions:\\n\")\n",
    "for i in range(5,10):\n",
    "    review_text = decode_review(x_test[i])\n",
    "    predicted_label = \"Positive\" if prediction >= 0.5 else \"Negative\"\n",
    "    print(f\"--- Review #{i+1} ---\")\n",
    "    print(\"Predicted:\", predicted_label)\n",
    "    print(\"Actual:   \", \"Positive\" if y_test[i] == 1 else \"Negative\")\n",
    "    print(\"Review:\", review_text[:300], \"...\")  # Print first 300 characters\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "253516ec-fe14-41db-98bd-8772a85c78b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IF dataset is available in csv file then make some changes in above code\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer # add this one also\n",
    "\n",
    "\n",
    "df = pd.read_csv('imdb_reviews.csv') \n",
    "df['sentiment'] = df['sentiment'].map({'positive': 1, 'negative': 0})\n",
    "\n",
    "#  Split the data into training and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(df['review'], df['sentiment'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Tokenize the text\n",
    "num_words = 10000  # Vocabulary size\n",
    "tokenizer = Tokenizer(num_words=num_words, oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts(x_train)\n",
    "\n",
    "x_train_seq = tokenizer.texts_to_sequences(x_train)\n",
    "x_test_seq = tokenizer.texts_to_sequences(x_test)\n",
    "\n",
    "# After that same steps like above\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d048736-73b2-48de-b66a-3706591dba2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
